{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, coint\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import requests\n",
    "import openpyxl\n",
    "from openpyxl.styles import Alignment\n",
    "from itertools import combinations, groupby, product\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date, datetime\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import corr_trading as corr_trading\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_classes =[\"equity\", 'crypto'] # See asset classes in the Extract Fin data repository for possible values\n",
    "\n",
    "# Location\n",
    "general_path = \"/Users/arenquiestas/Documents/Projects/\"\n",
    "project_path = f\"{general_path}Correlation Pairs Trading\"\n",
    "## Financial Data Database\n",
    "sql_file_path = '/Users/arenquiestas/Documents/Projects/Financial Data Extract/Output/FINANCIAL DATA.db'\n",
    "\n",
    "years_active = 10  # Number of years\n",
    "years_analysis = 10\n",
    "# years_train = 10\n",
    "top_traded = 4000\n",
    "max_price = 10000 # applies to current price, and when taking positions\n",
    "benchmark_ticker = '^GSPC'\n",
    "risk_free_prox = 'US 10-Year Treasury Yield'\n",
    "# Parameters:\n",
    "correlation_method = \"pearson\"\n",
    "\n",
    "# recalculate_corr_pairs = \"Y\"\n",
    "recalculate_engle_granger = \"NEW\"  # [NEW,ALL,NO]\n",
    "engle_granger_sig_level = 0.01\n",
    "recalculate_johansen = \"NEW\"  # [NEW,ALL,NO]\n",
    "johansen_sig_level = 0.01\n",
    "johansen_det_order = 0\n",
    "johansen_k_ar_diff = 1\n",
    "update_pairing = \"N\"\n",
    "\n",
    "cl_sp = 0.95 # Confidence level for Spread Deviation\n",
    "cl_st = 0.75 # Confidence level for Price Deviation\n",
    "maintain_threshold = 0.05 # Hold the position until the price is within cl_st - maintian within the mean. Default is 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers = corr_trading.load_sql_table('TICKERS_INFO',sql_file_path) \n",
    "dropped_tickers = corr_trading.load_sql_table('TICKERS_DROPPED',sql_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Free Rate converted to daily\n"
     ]
    }
   ],
   "source": [
    "# Load Index Data for Benchmarking\n",
    "\n",
    "# Find the latest CSV file and read it into a DataFrame\n",
    "index = corr_trading.load_sql_table('INDICES',sql_file_path) \n",
    "index = index[['Date', 'Ticker', 'Adj Close']]\n",
    "\n",
    "# Filter, rename, set index, and calculate returns\n",
    "benchmark = (index[index['Ticker'] == benchmark_ticker]\n",
    "             .rename(columns={'Adj Close': 'market'})\n",
    "             .set_index('Date')\n",
    "             .loc[:, ['market']])\n",
    "\n",
    "# Calculate the returns\n",
    "benchmark['market_return_usd'] = benchmark['market'].diff()\n",
    "benchmark['market_return_pct'] = benchmark['market'].pct_change()\n",
    "\n",
    "# Add the MultiIndex\n",
    "benchmark = benchmark.pipe(lambda df: df.set_axis(pd.MultiIndex.from_product([['Benchmark'], benchmark.columns]), axis=1))\n",
    "\n",
    "fred = corr_trading.load_sql_table('FRED',sql_file_path)\n",
    "fred = fred[['Date',risk_free_prox]]\n",
    "fred[risk_free_prox] = fred[risk_free_prox]/100 # convert to decimal\n",
    "fred[risk_free_prox] =(1 + fred[risk_free_prox] / 100) ** (1/252) - 1  # Assuming 252 trading days in a year\n",
    "print('Risk Free Rate converted to daily')\n",
    "risk_free = fred.set_index('Date').rename(columns={risk_free_prox:'risk_free_rate'})\n",
    "risk_free = risk_free.pipe(lambda df: df.set_axis(pd.MultiIndex.from_product([['Benchmark'], risk_free.columns]), axis=1))\n",
    "# risk_free['risk_free_rate'] = risk_free['risk_free_rate']/100\n",
    "\n",
    "\n",
    "benchmark = pd.merge(left = risk_free, \n",
    "                     right = benchmark,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equity asset class read\n",
      "crypto asset class read\n"
     ]
    }
   ],
   "source": [
    "fin_data = corr_trading.read_fin_data(asset_classes,sql_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped tickers removed\n",
      "Filtered to years_active > 10\n"
     ]
    }
   ],
   "source": [
    "fin_data = corr_trading.remove_dropped(df=fin_data, dropped_df=dropped_tickers)\n",
    "\n",
    "# Filter securities to include only those that have been active for at least the past 'y' years.\n",
    "fin_data = corr_trading.filter_years(\n",
    "    df=fin_data,\n",
    "    all_tickers_df=all_tickers,\n",
    "    years_active=years_active,\n",
    "    start_time=start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5820   2014-05-06 13:30:00\n",
       "Name: firstTradeDateEpochUtc, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers with latest price above $10000 removed\n"
     ]
    }
   ],
   "source": [
    "fin_data = fin_data.set_index([\"Date\"])\n",
    "\n",
    "# Optional. Filter to Tickers wherein the latest price is < $10000.\n",
    "filtered_df = fin_data[fin_data.index == fin_data.index[-1]]\n",
    "filtered_df = filtered_df[filtered_df['Adj Close'] <= max_price]\n",
    "fin_data = fin_data[fin_data['Ticker'].isin(filtered_df['Ticker'])]\n",
    "fin_data = fin_data.reset_index()\n",
    "print(f'Tickers with latest price above ${max_price} removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equity stocks filtered to Top 4000 most traded\n",
      "Missing values interpolated.\n",
      "Tickers with NaN after all of the filters above have been removed\n"
     ]
    }
   ],
   "source": [
    "# Filter equity stocks to retain only the top 'n' most-traded stocks. This filtering applies exclusively to equity stocks.\n",
    "fin_data = corr_trading.filter_most_traded(df=fin_data, top_n=top_traded)\n",
    "\n",
    "\n",
    "# Pivot the data to have tickers as columns and 'Adj Close' as values\n",
    "fin_data = fin_data.set_index(\"Date\")[[\"Adj Close\", \"Ticker\"]]\n",
    "fin_data2 = fin_data.pivot(columns=\"Ticker\", values=\"Adj Close\")\n",
    "\n",
    "\n",
    "# Identify tickers where the last row contains NaN values and drop those tickers\n",
    "nan_columns = fin_data2.columns[fin_data2.iloc[-1].isna()]\n",
    "fin_data2.drop(columns=nan_columns, inplace=True)\n",
    "\n",
    "\n",
    "# Filter financial data to last 'years_analysis' years\n",
    "fin_data2 = fin_data2.tail(252 * years_analysis)\n",
    "\n",
    "# Handle NaN values in DataFrame by interpolation\n",
    "fin_data2 = corr_trading.handle_nan(fin_data2)\n",
    "\n",
    "## Remove Tickers with NaN. This is necessary because interpolation will only handle NaN in between 2 non-NaN cells.\n",
    "### Some tickers may have gone public but prices are not available in YahooFinance until after some time. Example: all_tickers[all_tickers['Ticker'] == 'BIVI'][\"firstTradeDateEpochUtc\"]\n",
    "fin_data2.dropna(axis=1, how=\"any\", inplace=True)\n",
    "print('Tickers with NaN after all of the filters above have been removed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data3 = fin_data2.copy()\n",
    "\n",
    "# # Drop columns where all values are the same\n",
    "# fin_data3 = fin_data3.loc[:, (fin_data3 != fin_data3.iloc[0]).any()]\n",
    "\n",
    "ticker_list = fin_data3.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix\n",
    "\n",
    "**Pearson**: Measures the linear relationship between two continuous variables. Assumes a normal distribution and calculates the strength and direction of the linear relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "corr_matrix = fin_data3.corr(method=correlation_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cointegration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Johansen Test\n",
    "\n",
    "- **Cointegration Test: Johansen Test**\n",
    "  - The Johansen test evaluates whether multiple time series variables are cointegrated, indicating they share a stable long-term relationship despite short-term fluctuations. Unlike the Engle-Granger test, which examines pairwise relationships, Johansen's test handles multiple variables simultaneously to identify the number of cointegrating relationships and their associated vectors.\n",
    "- **Maximum Eigenvalue Statistic**\n",
    "\n",
    "  - In Johansen's test, the maximum eigenvalue statistic is one of the test statistics used to determine the presence of cointegration. It evaluates whether there is at least one cointegrating vector among the variables. The statistic is based on the largest eigenvalue of the system and provides insights into the strength of the most significant cointegrating relationship.\n",
    "\n",
    "- **Trace Statistic**\n",
    "\n",
    "  - The trace statistic in Johansen's test aggregates the eigenvalues across the system to assess the overall number of cointegrating vectors. It tests the null hypothesis that the number of cointegrating vectors is less than or equal to a specified number (typically the number of variables minus one). A significant trace statistic suggests the presence of cointegration.\n",
    "\n",
    "- **Critical Values**\n",
    "\n",
    "  - Critical values are thresholds determined from statistical tables or simulations that define the rejection regions for the test statistics (maximum eigenvalue and trace statistic). They indicate the cutoff points beyond which the test statistics' values are considered significant at a chosen significance level (e.g., 5% or 1%). Critical values vary based on the number of variables and the chosen significance level, and they are essential for interpreting the results of Johansen's test.\n",
    "\n",
    "- **Strength of Relationship**\n",
    "\n",
    "  - While cointegration itself doesn't quantify the strength of the relationship between variables, the test statistics and scores from Johansen's test provide insights into the magnitude of cointegration. Higher scores or more significant critical values indicate a stronger long-term relationship among the variables.\n",
    "\n",
    "- **Direction of Relationship**\n",
    "  - Johansen's test, like other cointegration tests, does not inherently determine the directionality (positive or negative) of the relationships. The direction is often interpreted based on economic theory or context specific to the variables being analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new combinations to be calculated\n",
      "\u001b[1mCointegration results exist for all combinations\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "johansen_results = corr_trading.calculate_johansen(\n",
    "    recalculate_johansen,\n",
    "    ticker_list,\n",
    "    fin_data3,\n",
    "    project_path,\n",
    "    det_order=0,\n",
    "    k_ar_diff=johansen_k_ar_diff,\n",
    "    johansen_sig_level=johansen_sig_level,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pairing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair stocks based on correlation, selecting the highest correlated pair that is cointegrated in both Engle-Granger and Johansen tests.\n",
    "\n",
    "if update_pairing == 'Y':\n",
    "    \n",
    "    pairs_0 = corr_trading.pairing(\n",
    "        corr_matrix,\n",
    "        johansen_results)\n",
    "\n",
    "    pairs_0 = pairs_0.sort_values(by=\"correlation\", ascending=False).reset_index(drop=True)\n",
    "    pairs_0.to_csv(f'/Users/arenquiestas/Documents/Projects/Correlation Pairs Trading/Outputs/2_Results/Pairing/PAIRS {datetime.now().strftime(\"%Y-%m-%d\")}.csv', index=False)\n",
    "\n",
    "elif update_pairing != 'Y':\n",
    "    \n",
    "    pairs_0_file = sorted([file for file in os.listdir(f'/Users/arenquiestas/Documents/Projects/Correlation Pairs Trading/Outputs/2_Results/Pairing') if file.endswith('.csv') and file.startswith('PAIRS')])[-1]\n",
    "    pairs_0 = pd.read_csv(f\"/Users/arenquiestas/Documents/Projects/Correlation Pairs Trading/Outputs/2_Results/Pairing/{pairs_0_file}\")\n",
    "\n",
    "pairs_list = pairs_0[[\"stock1\", \"stock2\"]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_1 = pd.DataFrame()\n",
    "pairs_1.index = fin_data3.index.copy()\n",
    "pairs_1.columns = pd.MultiIndex.from_tuples([], names=[\"\", \"\"])\n",
    "\n",
    "# Create a new DataFrame to store spreads and prices, with paired tickers indicated in the level 0 column\n",
    "for stock1, stock2 in zip(pairs_0[\"stock1\"], pairs_0[\"stock2\"]):\n",
    "    temp = fin_data3[[stock1, stock2]]\n",
    "    temp[\"spread\"] = temp[stock1] - temp[stock2]\n",
    "    temp.columns = pd.MultiIndex.from_product([[f\"{stock1}_{stock2}\"], temp.columns])\n",
    "    pairs_1 = pd.merge(\n",
    "        left=pairs_1, right=temp, right_index=True, left_index=True, how=\"outer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deviation Threshold: Z-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Absolute Return (Z-Score Spread: 0.95, Stock: 0.75,  Maintain: 0.05): 174.38404393196106\n"
     ]
    }
   ],
   "source": [
    "pairs_z_score = corr_trading.dev_thresh_z_score(\n",
    "    pairs_list=pairs_list,\n",
    "    pairs_df=pairs_1,\n",
    "    cl_spread= cl_sp,\n",
    "    cl_stock= cl_st)\n",
    "\n",
    "# Append Risk Free Rate and Market Returns\n",
    "pairs_z_score = pd.merge(left = pairs_z_score,\n",
    "                            right = benchmark,\n",
    "                            left_index=True,\n",
    "                            right_index=True,\n",
    "                            how = 'left')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame by selecting relevant columns and filling missing total returns with market returns\n",
    "\n",
    "metrics = pd.DataFrame()\n",
    "\n",
    "for pair in [a for a in pairs_z_score.columns.get_level_values(0).unique().to_list() if a != 'Benchmark']:\n",
    "    \n",
    "    # Calculate the excess return as the difference between total return and risk-free rate\n",
    "    pairs_z_score[(pair,'tot_return_pct')] = pairs_z_score[(pair,'tot_return_pct')].fillna(pairs_z_score[('Benchmark','market_return_pct')])\n",
    "    pairs_z_score[(pair,'excess_return_pct')] = pairs_z_score[(pair,'tot_return_pct')] - pairs_z_score[('Benchmark','risk_free_rate')]\n",
    "\n",
    "    df = pairs_z_score[[pair, 'Benchmark']].droplevel(level=0, axis=1)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Calculate the average excess return\n",
    "    average_excess_return_pct = df['excess_return_pct'].mean()\n",
    "\n",
    "    # Calculate downside deviation for negative excess returns\n",
    "    downside_returns = df['tot_return_pct'][df['tot_return_pct'] < 0]\n",
    "    downside_deviation = np.std(downside_returns) if len(downside_returns) > 0 else 0\n",
    "\n",
    "    # Calculate the standard deviation of all total returns for Sharpe Ratio\n",
    "    total_deviation = np.std(df['tot_return_pct'])\n",
    "\n",
    "    # Calculate Beta using linear regression (slope of the regression line)\n",
    "    X = sm.add_constant(df['market_return_pct'])  # Add a constant term for the intercept\n",
    "    model = sm.OLS(df['tot_return_pct'], X).fit()\n",
    "    beta = model.params[1]  # The slope coefficient represents Beta\n",
    "\n",
    "    # Calculate expected return using the CAPM formula\n",
    "    expected_return = df['risk_free_rate'].mean() + beta * (df['market_return_pct'].mean() - df['risk_free_rate'].mean())\n",
    "\n",
    "    # Calculate Jensen's Alpha\n",
    "    jensens_alpha = average_excess_return_pct - (expected_return - df['risk_free_rate'].mean())\n",
    "\n",
    "    # Calculate the Sortino Ratio\n",
    "    sortino_ratio = average_excess_return_pct / downside_deviation if downside_deviation != 0 else np.nan\n",
    "\n",
    "    # Calculate the Sharpe Ratio\n",
    "    sharpe_ratio = average_excess_return_pct / total_deviation if total_deviation != 0 else np.nan\n",
    "\n",
    "    # Calculate the Treynor Ratio\n",
    "    treynor_ratio = average_excess_return_pct / beta if beta != 0 else np.nan\n",
    "\n",
    "    # Calculate Tracking Error (standard deviation of the difference between portfolio and market returns)\n",
    "    tracking_error = np.std(df['tot_return_pct'] - df['market_return_pct'])\n",
    "\n",
    "    # Calculate Information Ratio\n",
    "    information_ratio = average_excess_return_pct / tracking_error if tracking_error != 0 else np.nan\n",
    "\n",
    "    # Trade Metrics\n",
    "\n",
    "    # Calculate the best and worst trades in USD and percentage\n",
    "    best_trade_usd = df[\"tot_return_usd\"].max()\n",
    "    best_trade_pct = df[\"tot_return_pct\"].max()\n",
    "    worst_trade_usd = df[\"tot_return_usd\"].min()\n",
    "    worst_trade_pct = df[\"tot_return_pct\"].min()\n",
    "\n",
    "    # Calculate average win and loss metrics\n",
    "    average_win_usd = df.loc[df[\"tot_return_usd\"] > 0, \"tot_return_usd\"].mean()\n",
    "    average_win_pct = df.loc[df[\"tot_return_pct\"] > 0, \"tot_return_pct\"].mean()\n",
    "    average_loss_usd = df.loc[df[\"tot_return_usd\"] < 0, \"tot_return_usd\"].mean()\n",
    "    average_loss_pct = df.loc[df[\"tot_return_pct\"] < 0, \"tot_return_pct\"].mean()\n",
    "\n",
    "    # Calculate average trade return\n",
    "    average_trade_return_usd = df[\"tot_return_usd\"].mean()\n",
    "    average_trade_return_pct = df[\"tot_return_pct\"].mean()\n",
    "\n",
    "    # Calculate total trade return\n",
    "    total_trade_return = df[\"tot_return_usd\"].sum()\n",
    "\n",
    "    # Calculate trade winning percentage\n",
    "    try:\n",
    "        trade_winning_percentage = len(df[df[\"tot_return_usd\"] > 0]) / len(df[df[f'position_{pair.split(\"_\")[0]}'] != \"\"])\n",
    "    except ZeroDivisionError:\n",
    "        trade_winning_percentage = 0  # Handle case where there are no trades\n",
    "\n",
    "    num_trade = len(df[df[f'position_{pair.split(\"_\")[0]}'] != ''])\n",
    "    df2 = df[['Date',f'position_{pair.split(\"_\")[0]}']]\n",
    "    df2 = df2.rename(columns={f'position_{pair.split(\"_\")[0]}':'Position'})\n",
    "    average_days_live = corr_trading.calculate_average_days_live(df2)\n",
    "\n",
    "    # Extract month and year from the Date column for aggregation\n",
    "    df['Month'] = df['Date'].dt.to_period('M')\n",
    "    df['Year'] = df['Date'].dt.to_period('Y')\n",
    "    df['Return'] = df['tot_return_usd']\n",
    "\n",
    "    # Aggregate returns by month\n",
    "    monthly_returns = df.groupby('Month')['Return'].sum()\n",
    "\n",
    "    # Aggregate returns by year\n",
    "    yearly_returns = df.groupby('Year')['Return'].sum()\n",
    "\n",
    "    # Calculate monthly metrics\n",
    "    num_months = len(monthly_returns)\n",
    "    num_winning_months = len(monthly_returns[monthly_returns > 0])\n",
    "    num_losing_months = len(monthly_returns[monthly_returns < 0])\n",
    "\n",
    "    # Calculate winning months percentage\n",
    "    winning_months_percentage = (num_winning_months / num_months) * 100 if num_months > 0 else 0\n",
    "\n",
    "    # Calculate average returns for winning and losing months\n",
    "    avg_return_winning_month = monthly_returns[monthly_returns > 0].mean() if num_winning_months > 0 else 0\n",
    "    avg_return_losing_month = monthly_returns[monthly_returns < 0].mean() if num_losing_months > 0 else 0\n",
    "\n",
    "    # Get best and worst month returns\n",
    "    best_month_return = monthly_returns.max()\n",
    "    worst_month_return = monthly_returns.min()\n",
    "\n",
    "    # Calculate yearly metrics\n",
    "    num_years = len(yearly_returns)\n",
    "    num_winning_years = len(yearly_returns[yearly_returns > 0])\n",
    "    num_losing_years = len(yearly_returns[yearly_returns < 0])\n",
    "\n",
    "    # Calculate winning years percentage\n",
    "    winning_years_percentage = (num_winning_years / num_years) * 100 if num_years > 0 else 0\n",
    "\n",
    "    # Calculate average returns for winning and losing years\n",
    "    avg_return_winning_year = yearly_returns[yearly_returns > 0].mean() if num_winning_years > 0 else 0\n",
    "    avg_return_losing_year = yearly_returns[yearly_returns < 0].mean() if num_losing_years > 0 else 0\n",
    "\n",
    "    # Get best and worst year returns\n",
    "    best_year_return = yearly_returns.max()\n",
    "    worst_year_return = yearly_returns.min()\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    curve_metrics = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Sortino Ratio', \n",
    "            'Sharpe Ratio', \n",
    "            'Treynor Ratio', \n",
    "            'Jensen\\'s Alpha', \n",
    "            'Beta', \n",
    "            'Tracking Error', \n",
    "            'Information Ratio',\n",
    "        ],\n",
    "        'Value': [\n",
    "            sortino_ratio, \n",
    "            sharpe_ratio, \n",
    "            treynor_ratio, \n",
    "            jensens_alpha, \n",
    "            beta, \n",
    "            tracking_error, \n",
    "            information_ratio,\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    trade_metrics = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            \"Best Trade ($)\",\n",
    "            \"Best Trade (%)\",\n",
    "            \"Worst Trade ($)\",\n",
    "            \"Worst Trade (%)\",\n",
    "            \"Average Win ($)\",\n",
    "            \"Average Win (%)\",\n",
    "            \"Average Loss ($)\",\n",
    "            \"Average Loss (%)\",\n",
    "            \"Average Trade Return ($)\",\n",
    "            \"Average Trade Return (%)\",\n",
    "            'Winning Trade (%)',\n",
    "            'Total Return ($)',\n",
    "            'Number of Trades',\n",
    "            'Avg. Days in Trade'\n",
    "        ],\n",
    "        'Value': [\n",
    "            best_trade_usd,\n",
    "            best_trade_pct,\n",
    "            worst_trade_usd,\n",
    "            worst_trade_pct,\n",
    "            average_win_usd,\n",
    "            average_win_pct,\n",
    "            average_loss_usd,\n",
    "            average_loss_pct,\n",
    "            average_trade_return_usd,\n",
    "            average_trade_return_pct,\n",
    "            trade_winning_percentage,\n",
    "            total_trade_return,\n",
    "            num_trade,\n",
    "            average_days_live\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    time_metrics = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            \"Winning Years (%)\",\n",
    "            \"Average Return for Winning Year (%)\",\n",
    "            \"Average Return for Losing Year (%)\",\n",
    "            \"Best Year Return (%)\",\n",
    "            \"Worst Year Return (%)\",\n",
    "            \"Winning Months (%)\",\n",
    "            \"Average Return for Winning Month (%)\",\n",
    "            \"Average Return for Losing Month (%)\",\n",
    "            \"Best Month (% Return)\",\n",
    "            \"Worst Month (% Return)\",\n",
    "        ],\n",
    "        'Value': [\n",
    "            winning_years_percentage,\n",
    "            avg_return_winning_year,\n",
    "            avg_return_losing_year,\n",
    "            best_year_return,\n",
    "            worst_year_return,\n",
    "            winning_months_percentage,\n",
    "            avg_return_winning_month,\n",
    "            avg_return_losing_month,\n",
    "            best_month_return,\n",
    "            worst_month_return\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Final DF\n",
    "    for x,y in zip(['curve_metrics','trade_metrics','time_metrics'], ['CURVE','TRADE','TIME']):\n",
    "        globals()[x] = globals()[x].set_index('Metric').T\n",
    "        new_columns = pd.MultiIndex.from_product([[y], globals()[x].columns], names=[None,None])\n",
    "        globals()[x].columns = new_columns\n",
    "        \n",
    "    temp = pd.concat([curve_metrics,\n",
    "                            trade_metrics,\n",
    "                            time_metrics], axis =1)\n",
    "    temp['PAIR'] = pair\n",
    "    temp = temp.set_index('PAIR')\n",
    "    \n",
    "    metrics = pd.concat([metrics,temp])\n",
    "    \n",
    "metrics.to_excel(f'{project_path}/Outputs/2_Results/Trade Metrics/Metrics.xlsx', sheet_name='METRICS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Trade Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade signals for: ['HRTG_ITP']\n"
     ]
    }
   ],
   "source": [
    "curr_day_positions = []\n",
    "curr_day_index = pairs_z_score.index[-1]\n",
    "\n",
    "# list_of_cols\n",
    "temp_list = [[level_0] + [col for col in pairs_z_score[level_0].columns if 'position' in col.lower()]\n",
    "               for level_0 in pairs_z_score.columns.levels[0]]\n",
    "temp_list = [item for item in temp_list if len(item) > 1]\n",
    "\n",
    "\n",
    "# Identify the level 1 columns containing 'position'\n",
    "for pairs in temp_list:\n",
    "    temp_df = pairs_z_score[pairs[0]]\n",
    "    if temp_df.iloc[-1][pairs[1]] and temp_df.iloc[-1][pairs[2]]:\n",
    "            curr_day_positions.append(pairs[0])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Create a new df where positions are to be taken\n",
    "todays_trade_signals = pairs_z_score.loc[:, pairs_z_score.columns.get_level_values(0).isin(curr_day_positions + ['Benchmark'])]\n",
    "\n",
    "if todays_trade_signals.empty:\n",
    "        print('No trade signals today')\n",
    "else:\n",
    "        print(f'Trade signals for: {curr_day_positions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_list = []\n",
    "curve_table_list = []\n",
    "trade_table_list = []\n",
    "time_table_list = []\n",
    "\n",
    "for pair in curr_day_positions:\n",
    "    temp = todays_trade_signals[[pair,'Benchmark']]\n",
    "    temp = temp.droplevel(level=0, axis=1)\n",
    "    temp = temp[[col for col in todays_trade_signals[['HRTG_ITP','Benchmark']].droplevel(level=0, axis=1).columns.tolist() \n",
    "                    if col.endswith('pct')\n",
    "                    or col == 'risk_free_rate']]\n",
    "    \n",
    "    temp['return_cumulative_market'] = (1 + temp['market_return_pct']).cumprod() - 1\n",
    "    temp['return_cumulative_pair'] = (1 + temp['tot_return_pct']).cumprod() - 1\n",
    "    \n",
    "    globals()[f'fig_{pair.lower()}'] = go.Figure()\n",
    "    \n",
    "    # Add first time series\n",
    "    globals()[f'fig_{pair.lower()}'].add_trace(go.Scatter(x=temp.index, y=temp['return_cumulative_market'], mode='lines', name='Cumulative Market Return', line=dict(color='blue')))\n",
    "\n",
    "    # Add second time series\n",
    "    globals()[f'fig_{pair.lower()}'].add_trace(go.Scatter(x=temp.index, y=temp['return_cumulative_pair'], mode='lines', name='Cumulative Pairs_Strategy Return', line=dict(color='green')))\n",
    "\n",
    "        # Update layout\n",
    "    globals()[f'fig_{pair.lower()}'].update_layout(\n",
    "        title='Cumulative Market Returns',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_tickformat='.1%',\n",
    "        yaxis_title='Cumulative Return (%)',\n",
    "        legend_title='Legend',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    globals()[f'fig_html_{pair.lower()}'] = pio.to_html(globals()[f'fig_{pair.lower()}'], full_html=False)\n",
    "    \n",
    "    fig_list.append(f'fig_html_{pair.lower()}')\n",
    "    \n",
    "    # HTML Tables\n",
    "    \n",
    "    ### Curve Metrics\n",
    "    temp = metrics.loc[[pair]]\n",
    "    temp = temp['CURVE'].T\n",
    "    temp.columns.name = None\n",
    "    \n",
    "    html_table = temp.to_html()\n",
    "    headline = \"<h2>CURVE</h2>\"\n",
    "    globals()[f'curve_metrics_html_{pair.lower()}'] = headline + html_table\n",
    "\n",
    "    globals()[f'curve_metrics_html_{pair.lower()}'] = globals()[f'curve_metrics_html_{pair.lower()}'].replace('<thead>', '<thead style=\"background-color: white; color: black;\">')\n",
    "    # Change body fill color to white and text color to black\n",
    "    globals()[f'curve_metrics_html_{pair.lower()}'] = globals()[f'curve_metrics_html_{pair.lower()}'].replace('<tbody>', '<tbody style=\"background-color: white; color: black;\">')\n",
    "\n",
    "    curve_table_list.append(f'curve_metrics_html_{pair.lower()}')\n",
    "\n",
    "    ### Trade Metrics\n",
    "    temp = metrics.loc[[pair]]\n",
    "    temp = temp['TRADE'].T\n",
    "    temp.columns.name = None\n",
    "    \n",
    "    html_table = temp.to_html()\n",
    "    headline = \"<h2>TRADE</h2>\"\n",
    "    globals()[f'trade_metrics_html_{pair.lower()}'] = headline + html_table\n",
    "\n",
    "    globals()[f'trade_metrics_html_{pair.lower()}'] = globals()[f'trade_metrics_html_{pair.lower()}'].replace('<thead>', '<thead style=\"background-color: white; color: black;\">')\n",
    "    # Change body fill color to white and text color to black\n",
    "    globals()[f'trade_metrics_html_{pair.lower()}'] = globals()[f'trade_metrics_html_{pair.lower()}'].replace('<tbody>', '<tbody style=\"background-color: white; color: black;\">')\n",
    "\n",
    "    trade_table_list.append(f'trade_metrics_html_{pair.lower()}')\n",
    "    \n",
    "    ### Time Metrics\n",
    "    temp = metrics.loc[[pair]]\n",
    "    temp = temp['TIME'].T\n",
    "    temp.columns.name = None\n",
    "    \n",
    "    html_table = temp.to_html()\n",
    "    headline = \"<h2>TIME</h2>\"\n",
    "    globals()[f'time_metrics_html_{pair.lower()}'] = headline + html_table\n",
    "\n",
    "    globals()[f'time_metrics_html_{pair.lower()}'] = globals()[f'time_metrics_html_{pair.lower()}'].replace('<thead>', '<thead style=\"background-color: white; color: black;\">')\n",
    "    # Change body fill color to white and text color to black\n",
    "    globals()[f'time_metrics_html_{pair.lower()}'] = globals()[f'time_metrics_html_{pair.lower()}'].replace('<tbody>', '<tbody style=\"background-color: white; color: black;\">')\n",
    "\n",
    "    time_table_list.append(f'time_metrics_html_{pair.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard for HRTG_ITP saved in /Users/arenquiestas/Documents/Projects/Correlation Pairs Trading/Outputs/3_Signals/RUN_20240826\n"
     ]
    }
   ],
   "source": [
    "# Combine all tables\n",
    "\n",
    "signals_path = f'{project_path}/Outputs/3_Signals/RUN_{start_time.strftime(\"%Y%m%d\")}'\n",
    "\n",
    "if not os.path.exists(signals_path):\n",
    "    os.makedirs(signals_path)\n",
    "    print(f'{signals_path} Created')\n",
    "\n",
    "\n",
    "for fig, c_table, tr_table, ti_table, pair in zip(fig_list, curve_table_list, trade_table_list, time_table_list, curr_day_positions):\n",
    "    html_content = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html lang=\"en\">\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\">\n",
    "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            <title>Plotly Graph with Tables</title>\n",
    "            <style>\n",
    "                /* Add some basic styling */\n",
    "                body {{\n",
    "                    font-family: Arial, sans-serif;\n",
    "                    margin: 20px;\n",
    "                }}\n",
    "\n",
    "                table {{\n",
    "                    width: 100%;\n",
    "                    border-collapse: collapse;\n",
    "                    margin-top: 20px;\n",
    "                }}\n",
    "\n",
    "                th, td {{\n",
    "                    padding: 10px;\n",
    "                    border: 1px solid #ddd;\n",
    "                    text-align: left;\n",
    "                }}\n",
    "\n",
    "                th {{\n",
    "                    background-color: #f4f4f4;\n",
    "                }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "\n",
    "            <h1>Plotly Graph with Tables</h1>\n",
    "\n",
    "            <!-- Plotly Graph -->\n",
    "            <div id=\"plotly_graph\">\n",
    "                {globals()[fig]}\n",
    "            </div>\n",
    "\n",
    "            <!-- HTML Table 1 -->\n",
    "            {globals()[c_table]}\n",
    "\n",
    "            <!-- HTML Table 2 -->\n",
    "            {globals()[tr_table]}\n",
    "            \n",
    "            <!-- HTML Table 3 -->\n",
    "            {globals()[ti_table]}\n",
    "\n",
    "            <!-- Include the Plotly.js library -->\n",
    "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "\n",
    "        # Save the combined HTML to a file\n",
    "    with open(f'{signals_path}/{pair}-{start_time.strftime(\"%Y-%m-%d\")}.html', 'w') as file:\n",
    "        file.write(html_content)\n",
    "    \n",
    "    print(f'Dashboard for {pair} saved in {signals_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notified\n"
     ]
    }
   ],
   "source": [
    "def send_imessage(phone_number, message):\n",
    "    \"\"\"\n",
    "    Send an iMessage to a specified phone number.\n",
    "    \n",
    "    :param phone_number: The recipient's phone number.\n",
    "    :param message: The message to send.\n",
    "    \"\"\"\n",
    "    apple_script = f'''\n",
    "    tell application \"Messages\"\n",
    "        set targetService to 1st service whose service type = iMessage\n",
    "        set targetBuddy to buddy \"{phone_number}\" of targetService\n",
    "        send \"{message}\" to targetBuddy\n",
    "    end tell\n",
    "    '''\n",
    "    \n",
    "    subprocess.run(['osascript', '-e', apple_script])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    phone_number = \"+447588448586\"  # Replace with your phone number\n",
    "    message = f'''Correlation Pairs Trading\n",
    "        Start: {start_time.strftime(\"%Y-%m-%d  %H:%M\")}\n",
    "        End: {datetime.now().strftime(\"%Y-%m-%d  %H:%M\")}\n",
    "        Trade Signals for: {curr_day_positions}\n",
    "            '''\n",
    "    \n",
    "    send_imessage(phone_number, message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
